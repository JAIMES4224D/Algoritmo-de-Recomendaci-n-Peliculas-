# -*- coding: utf-8 -*-
"""ScriptMaestro.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NH9mOQ9VhVuSHSwwKjPQfjrNoOzRtMNV
"""

import pandas as pd
import ast
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

print("âœ… Â¡LibrerÃ­as importadas!")

print("Cargando los 3 archivos CSV originales...")
try:
    df_meta = pd.read_csv('movies_metadata.csv', low_memory=False)
    df_credits = pd.read_csv('credits.csv')
    df_keywords = pd.read_csv('keywords.csv')
    print("Archivos cargados.")
except FileNotFoundError:
    print("\nÂ¡ERROR! ðŸ›‘ No se encontraron los 3 archivos CSV originales.")
    print("Sube 'movies_metadata.csv', 'credits.csv' y 'keywords.csv' y re-ejecuta.")

# --- Limpieza de IDs (El paso clave antes de unir) ---
print("Limpiando IDs para la fusiÃ³n...")
df_meta['id'] = pd.to_numeric(df_meta['id'], errors='coerce')
df_meta = df_meta.dropna(subset=['id'])
df_meta['id'] = df_meta['id'].astype(int)

df_keywords['id'] = df_keywords['id'].astype(int)
df_credits['id'] = df_credits['id'].astype(int)

# --- FusiÃ³n (Merge) ---
print("Fusionando los 3 archivos...")
df = df_meta.merge(df_keywords, on='id', how='left')
df = df.merge(df_credits, on='id', how='left')

# (Opcional) Eliminar duplicados de 'id' que pudieron surgir
df = df.drop_duplicates(subset='id').reset_index(drop=True)

print(f"âœ… Â¡FusiÃ³n completada! Forma original del DataFrame: {df.shape}")

print(f"Reduciendo el DataFrame a las 10,000 pelÃ­culas mÃ¡s populares...")

# 1. Asegurarnos que 'popularity' sea un nÃºmero
# 'coerce' convierte los valores malos en NaT/NaN
df['popularity'] = pd.to_numeric(df['popularity'], errors='coerce')

# 2. Eliminar filas donde la popularidad sea NaN (si las hay)
df = df.dropna(subset=['popularity'])

# 3. Ordenar por popularidad (de mayor a menor) y tomar las 10,000 primeras
df = df.sort_values('popularity', ascending=False).head(10000)

# 4. Importante: Resetear el Ã­ndice
# Esto es vital para que el mapeo (indices) funcione despuÃ©s
df = df.reset_index(drop=True)

print(f"âœ… Â¡Dataset reducido! Nueva forma: {df.shape}")

print("Definiendo funciones de 'parsing' (limpieza)...")

def safe_literal_eval(s):
    try:
        return ast.literal_eval(s)
    except (ValueError, SyntaxError, TypeError):
        return []

def get_names(data_list_str):
    data_list = safe_literal_eval(data_list_str)
    if isinstance(data_list, list):
        names = [item['name'].lower().replace(" ", "") for item in data_list if 'name' in item]
        return names
    return []

def get_top_cast(cast_list_str, top_n=3):
    cast_list = safe_literal_eval(cast_list_str)
    if isinstance(cast_list, list):
        names = [item['name'].lower().replace(" ", "") for item in cast_list[:top_n] if 'name' in item]
        return names
    return []

def get_director(crew_list_str):
    crew_list = safe_literal_eval(crew_list_str)
    if isinstance(crew_list, list):
        for member in crew_list:
            if member.get('job') == 'Director':
                return member.get('name', '').lower().replace(" ", "")
    return ""

print("âœ… Â¡Funciones 'get_names', 'get_top_cast' y 'get_director' definidas!")

print("Iniciando la creaciÃ³n de la 'metadata_soup'...")

# 4a. Limpieza de NaNs (Paso 1: para parsing)
print("Limpiando NaNs (genres, keywords, cast, crew)...")
df['genres'] = df['genres'].fillna('[]')
df['keywords'] = df['keywords'].fillna('[]')
df['cast'] = df['cast'].fillna('[]')
df['crew'] = df['crew'].fillna('[]')

# 4b. Aplicar las funciones de parsing
print("Aplicando funciones (creando _list)...")
df['genres_list'] = df['genres'].apply(get_names)
df['keywords_list'] = df['keywords'].apply(get_names)
df['cast_list'] = df['cast'].apply(get_top_cast)
df['director'] = df['crew'].apply(get_director)

# 4c. Limpieza de NaNs (Paso 2: Fix del TypeError)
print("Limpiando NaNs (overview, director)...")
df['overview'] = df['overview'].fillna('')
df['director'] = df['director'].fillna('')

# 4d. Definir la funciÃ³n para crear la Sopa
def create_metadata_soup(row):
    genres = ' '.join(row['genres_list'])
    keywords = ' '.join(row['keywords_list'])
    cast = ' '.join(row['cast_list'])

    genres_weighted = (genres + ' ') * 2
    keywords_weighted = (keywords + ' ') * 3
    cast_weighted = (cast + ' ') * 3
    director_weighted = (row['director'] + ' ') * 3

    return (
        row['overview'] + ' ' +
        genres_weighted +
        keywords_weighted +
        cast_weighted +
        director_weighted
    )

# 4e. Aplicar la funciÃ³n para crear la Sopa
print("Aplicando 'create_metadata_soup'... (Esto tardarÃ¡ menos ahora)")
df['metadata_soup'] = df.apply(create_metadata_soup, axis=1)

print("\nâœ… Â¡'metadata_soup' creada exitosamente!")

print("Iniciando la VectorizaciÃ³n TF-IDF...")

tfidf = TfidfVectorizer(
    stop_words='english',
    max_features=10000  # Mantenemos 10k palabras, pero ahora sobre 10k pelÃ­culas
)
tfidf_matrix = tfidf.fit_transform(df['metadata_soup'])

print("\nâœ… Â¡VectorizaciÃ³n TF-IDF completada!")
print(f"Forma de la Matriz TF-IDF: {tfidf_matrix.shape}")

print("Calculando Similitud Coseno...")

# Â¡Esto ahora SÃ funcionarÃ¡ en Colab!
cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)

print("\nâœ… Â¡CÃ¡lculo de Similitud Coseno completado!")
print(f"Forma de la Matriz de Similitud: {cosine_sim.shape}")

print("Creando la funciÃ³n de recomendaciÃ³n... (Â¡VersiÃ³n CORREGIDA!)")

# --- Â¡FIX #1: CreaciÃ³n correcta del Mapeo de TÃ­tulo a Ãndice! ---
# 1. Crear la serie base
s = pd.Series(df.index, index=df['title'])

# 2. Filtrar la serie para ELIMINAR TÃTULOS DUPLICADOS (el '~' significa 'no')
#    Nos quedamos solo con la 'primera' apariciÃ³n de cada tÃ­tulo.
indices = s[~s.index.duplicated(keep='first')]

print("Mapeo de 'Ã­ndices' (sin duplicados) creado.")

# 2. Definir la funciÃ³n (con el FIX #2)
def get_recommendations(title, cosine_sim_matrix=cosine_sim, num_recommendations=10):

    # BÃºsqueda simple (esto estaba bien)
    if title not in indices:
        matching_titles = [t for t in indices.index if title.lower() in str(t).lower()]
        if not matching_titles:
            return f"Error: No se encontrÃ³ '{title}' ni tÃ­tulos similares en el Top 10k."
        print(f"No se encontrÃ³ '{title}'. Mostrando resultados para '{matching_titles[0]}'")
        title = matching_titles[0]

    # Obtener el Ã­ndice (la posiciÃ³n) de la pelÃ­cula
    idx = indices[title]

    # --- Â¡FIX #2: El "Seguro" para el ValueError! ---
    # Si 'idx' sigue siendo una lista (Serie de Pandas) porque el tÃ­tulo
    # aÃºn tiene duplicados (ej. 'Cinderella'), tomamos solo el PRIMERO.
    if isinstance(idx, pd.Series):
        idx = idx.iloc[0]
    # --- Fin del Fix ---

    # Obtener los puntajes de similitud (esta lÃ­nea ahora es segura)
    sim_scores = list(enumerate(cosine_sim_matrix[idx]))

    # Ordenar las pelÃ­culas por similitud
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)

    # Obtener las N mÃ¡s similares
    top_sim_scores = sim_scores[1 : num_recommendations + 1]

    # Obtener los Ã­ndices de esas pelÃ­culas
    movie_indices = [i[0] for i in top_sim_scores]

    # Devolver los tÃ­tulos
    return df['title'].iloc[movie_indices]

print("âœ… Â¡FunciÃ³n 'get_recommendations' (corregida) definida!")

print("--- [VALIDACIÃ“N CUALITATIVA] ---")

movie_title_1 = 'The Dark Knight'
print(f"\nRecomendaciones para: '{movie_title_1}'")
print("------------------------------------------")
print(get_recommendations(movie_title_1))

movie_title_2 = 'Inception'
print(f"\nRecomendaciones para: '{movie_title_2}'")
print("------------------------------------------")
print(get_recommendations(movie_title_2))

movie_title_3 = 'Pulp Fiction'
print(f"\nRecomendaciones para: '{movie_title_3}'")
print("------------------------------------------")
print(get_recommendations(movie_title_3, num_recommendations=5))

# Esta es la que probablemente dio el error. Â¡Ahora deberÃ­a funcionar!
movie_title_4 = 'A Nightmare on Elm Street'
print(f"\nRecomendaciones para: '{movie_title_4}'")
print("------------------------------------------")
print(get_recommendations(movie_title_4, num_recommendations=5))

print("\n--- [FIN] Â¡Sistema de recomendaciÃ³n (Top 10k) completo! ---")

#################################################################
# SCRIPT MAESTRO ÃšNICO: SISTEMA DE RECOMENDACIÃ“N (COMPLETO)
#
# Este script ejecuta todo el proceso:
# 1. Carga y FusiÃ³n de los 3 CSV originales.
# 2. SoluciÃ³n de RAM: Reduce el dataset al Top 10k mÃ¡s popular.
# 3. DefiniciÃ³n de Funciones de Limpieza (Parsing).
# 4. CreaciÃ³n de la 'Metadata Soup' (con fixes de TypeError).
# 5. GeneraciÃ³n de GrÃ¡ficos del EDA.
# 6. ConstrucciÃ³n del Modelo (TF-IDF y Similitud Coseno).
# 7. CreaciÃ³n de la FunciÃ³n de RecomendaciÃ³n (con fixes de ValueError).
# 8. ValidaciÃ³n final del modelo.
# 9.
#10.  VALIDACIÃ“N CIENTÃFICA (Matriz de Coherencia).
# 11.  DESPLIEGUE (GeneraciÃ³n de archivos .pkl para AWS).
#################################################################

print("--- [INICIO] INICIANDO PROCESO COMPLETO ---")

# --- 1. IMPORTAR LIBRERÃAS (TODAS JUNTAS) ---
print("\n[Paso 1/9] Importando librerÃ­as...")
import pandas as pd
import ast
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import sys
print("   > Â¡LibrerÃ­as importadas!")

# --- 2. CARGAR Y FUSIONAR (MERGE) LOS 3 ARCHIVOS ORIGINALES ---
print("\n[Paso 2/9] Cargando y fusionando (merge) los 3 archivos CSV...")
try:
    df_meta = pd.read_csv('movies_metadata.csv', low_memory=False)
    df_credits = pd.read_csv('credits.csv')
    df_keywords = pd.read_csv('keywords.csv')
    print("   > 3 archivos CSV cargados en memoria.")
except FileNotFoundError:
    print("\nÂ¡ERROR! ðŸ›‘ No se encontraron los 3 archivos CSV originales.")
    print("AsegÃºrate de tener 'movies_metadata.csv', 'credits.csv' y 'keywords.csv' en la misma carpeta.")
    # sys.exit() # DetendrÃ­a el script

# Limpieza de IDs (El paso clave antes de unir)
print("   > Limpiando IDs para la fusiÃ³n...")
df_meta['id'] = pd.to_numeric(df_meta['id'], errors='coerce')
df_meta = df_meta.dropna(subset=['id'])
df_meta['id'] = df_meta['id'].astype(int)

df_keywords['id'] = df_keywords['id'].astype(int)
df_credits['id'] = df_credits['id'].astype(int)

# FusiÃ³n (Merge)
print("   > Fusionando DataFrames...")
df = df_meta.merge(df_keywords, on='id', how='left')
df = df.merge(df_credits, on='id', how='left')

# Eliminar duplicados de 'id' que pudieron surgir
df = df.drop_duplicates(subset='id').reset_index(drop=True)
print(f"   > Â¡FusiÃ³n completada! Forma original: {df.shape}")

# --- 3. Â¡FIX DE RAM! REDUCIR EL DATASET AL TOP 10K ---
print("\n[Paso 3/9] SoluciÃ³n de RAM: Reduciendo el DataFrame al Top 10k...")

# 1. Asegurarnos que 'popularity' sea un nÃºmero
df['popularity'] = pd.to_numeric(df['popularity'], errors='coerce')
df = df.dropna(subset=['popularity'])

# 2. Ordenar por popularidad y tomar las 10,000 mejores
df = df.sort_values('popularity', ascending=False).head(10000)

# 3. Importante: Resetear el Ã­ndice (Clave para el Paso 7)
df = df.reset_index(drop=True)
print(f"   > Â¡Dataset reducido! Nueva forma: {df.shape}")

# --- 4. DEFINIR FUNCIONES DE LIMPIEZA (PARSING) ---
print("\n[Paso 4/9] Definiendo funciones de 'parsing'...")

def safe_literal_eval(s):
    try:
        return ast.literal_eval(s)
    except (ValueError, SyntaxError, TypeError):
        return []

def get_names(data_list_str):
    data_list = safe_literal_eval(data_list_str)
    if isinstance(data_list, list):
        names = [item['name'].lower().replace(" ", "") for item in data_list if 'name' in item]
        return names
    return []

def get_top_cast(cast_list_str, top_n=3):
    cast_list = safe_literal_eval(cast_list_str)
    if isinstance(cast_list, list):
        names = [item['name'].lower().replace(" ", "") for item in cast_list[:top_n] if 'name' in item]
        return names
    return []

def get_director(crew_list_str):
    crew_list = safe_literal_eval(crew_list_str)
    if isinstance(crew_list, list):
        for member in crew_list:
            if member.get('job') == 'Director':
                return member.get('name', '').lower().replace(" ", "")
    return ""
print("   > Funciones de limpieza definidas.")

# --- 5. CREAR LA 'METADATA SOUP' (CON FIXES DE TYPEERROR) ---
print("\n[Paso 5/9] Creando 'metadata_soup' (Limpieza y PonderaciÃ³n)...")

# 5a. Limpieza de NaNs (para parsing)
df['genres'] = df['genres'].fillna('[]')
df['keywords'] = df['keywords'].fillna('[]')
df['cast'] = df['cast'].fillna('[]')
df['crew'] = df['crew'].fillna('[]')

# 5b. Aplicar las funciones de parsing
print("   > Aplicando 'get_names', 'get_top_cast', 'get_director'...")
df['genres_list'] = df['genres'].apply(get_names)
df['keywords_list'] = df['keywords'].apply(get_names)
df['cast_list'] = df['cast'].apply(get_top_cast)
df['director'] = df['crew'].apply(get_director)

# 5c. Â¡FIX DE TYPEERROR! (float + str)
print("   > Aplicando fix de TypeError (limpiando 'overview' y 'director')...")
df['overview'] = df['overview'].fillna('')
df['director'] = df['director'].fillna('')

# 5d. Definir la funciÃ³n para crear la Sopa
def create_metadata_soup(row):
    genres = ' '.join(row['genres_list'])
    keywords = ' '.join(row['keywords_list'])
    cast = ' '.join(row['cast_list'])

    genres_weighted = (genres + ' ') * 2
    keywords_weighted = (keywords + ' ') * 3
    cast_weighted = (cast + ' ') * 3
    director_weighted = (row['director'] + ' ') * 3

    return (
        row['overview'] + ' ' +
        genres_weighted +
        keywords_weighted +
        cast_weighted +
        director_weighted
    )

# 5e. Aplicar la creaciÃ³n de la Sopa
print("   > Creando la 'sopa' final... (Esto tardarÃ¡ menos ahora)")
df['metadata_soup'] = df.apply(create_metadata_soup, axis=1)
print("   > Â¡'metadata_soup' creada!")

# --- 6. ANÃLISIS EXPLORATORIO DE DATOS (EDA) ---
print("\n[Paso 6/9] Generando grÃ¡ficos del AnÃ¡lisis Exploratorio (EDA)...")
sns.set(style="whitegrid")

# GrÃ¡fico 1: Tipo de Contenido
try:
    print("   > Generando GrÃ¡fico 1: Tipo de Contenido...")
    valid_types = ['Movie', 'TV Show']
    df_filtered_types = df[df['type'].isin(valid_types)]
    type_counts = df_filtered_types['type'].value_counts()
    plt.figure(figsize=(10, 6))
    sns.countplot(x='type', data=df_filtered_types, order=type_counts.index, palette="viridis")
    plt.title('ProporciÃ³n de PelÃ­culas vs. Series de TV (Top 10k Populares)', fontsize=16)
    plt.savefig('grafico_1_tipo_contenido.png')
    plt.close()
    print("   > GrÃ¡fico 1 guardado.")
except KeyError:
    print("   > ADVERTENCIA: Columna 'type' no encontrada. Omitiendo GrÃ¡fico 1.")

# GrÃ¡fico 2: AÃ±os de Estreno
print("   > Generando GrÃ¡fico 2: AÃ±os de Estreno...")
release_dates = pd.to_datetime(df['release_date'], errors='coerce')
release_years = release_dates.dt.year.dropna()
release_years = release_years[(release_years > 1900) & (release_years <= 2025)]
plt.figure(figsize=(14, 7))
sns.histplot(release_years, bins=60, kde=False, color="blue")
plt.title('DistribuciÃ³n de AÃ±os de Estreno (Top 10k Populares)', fontsize=16)
plt.savefig('grafico_2_anios_estreno.png')
plt.close()
print("   > GrÃ¡fico 2 guardado.")

# GrÃ¡fico 3: Top 15 GÃ©neros
print("   > Generando GrÃ¡fico 3: Top 15 GÃ©neros...")
genres_exploded = df.explode('genres_list')
top_genres = genres_exploded[genres_exploded['genres_list'] != '']['genres_list'].value_counts().head(15)
plt.figure(figsize=(14, 8))
sns.barplot(x=top_genres.values, y=top_genres.index, palette='mako')
plt.title('Top 15 GÃ©neros MÃ¡s Comunes (Top 10k Populares)', fontsize=16)
plt.savefig('grafico_3_top_generos.png')
plt.close()
print("   > GrÃ¡fico 3 guardado.")

# GrÃ¡fico 4: DistribuciÃ³n de Calificaciones
print("   > Generando GrÃ¡fico 4: DistribuciÃ³n de Calificaciones...")
df['vote_average'] = pd.to_numeric(df['vote_average'], errors='coerce')
votos_reales = df[df['vote_average'] > 0]['vote_average']
plt.figure(figsize=(12, 7))
sns.histplot(votos_reales, bins=40, kde=True, color="purple")
plt.title('DistribuciÃ³n de Calificaciones Promedio (Top 10k Populares)', fontsize=16)
mean_val = votos_reales.mean()
plt.axvline(mean_val, color='red', linestyle='--', label=f'Promedio: {mean_val:.2f}')
plt.legend()
plt.savefig('grafico_4_distribucion_votos.png')
plt.close()
print("   > GrÃ¡fico 4 guardado.")

# GrÃ¡fico 5: Matriz de CorrelaciÃ³n
print("   > Generando GrÃ¡fico 5: Matriz de CorrelaciÃ³n...")
df['budget'] = pd.to_numeric(df['budget'], errors='coerce')
df['revenue'] = pd.to_numeric(df['revenue'], errors='coerce')
df['runtime'] = pd.to_numeric(df['runtime'], errors='coerce')
df['vote_count'] = pd.to_numeric(df['vote_count'], errors='coerce')
df_numeric = df[
    (df['budget'] > 1000) & (df['revenue'] > 1000) & (df['vote_count'] > 100)
][['budget', 'revenue', 'popularity', 'runtime', 'vote_average', 'vote_count']]
corr_matrix = df_numeric.corr()
plt.figure(figsize=(12, 8))
sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm', linewidths=.5)
plt.title('Matriz de CorrelaciÃ³n (Top 10k Populares)', fontsize=16)
plt.savefig('grafico_5_correlacion.png')
plt.close()
print("   > GrÃ¡fico 5 guardado.")
print("   > Â¡EDA Completo!")

# --- 7. CONSTRUCCIÃ“N DEL MODELO (TF-IDF) ---
print("\n[Paso 7/9] Construyendo el modelo (TF-IDF)...")
tfidf = TfidfVectorizer(
    stop_words='english',
    max_features=10000  # Usar 10k palabras en nuestro dataset de 10k pelÃ­culas
)
tfidf_matrix = tfidf.fit_transform(df['metadata_soup'])
print(f"   > Matriz TF-IDF creada. Forma: {tfidf_matrix.shape}")

# --- 8. CONSTRUCCIÃ“N DEL MODELO (SIMILITUD COSENO) ---
print("\n[Paso 8/9] Construyendo el modelo (Similitud Coseno)...")
# Â¡Esto ahora SÃ funcionarÃ¡ en Colab!
cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)
print(f"   > Matriz de Similitud creada. Forma: {cosine_sim.shape}")

# --- 9. FUNCIÃ“N DE RECOMENDACIÃ“N Y VALIDACIÃ“N (CON FIX DE VALUEERROR) ---
print("\n[Paso 9/9] Creando funciÃ³n de recomendaciÃ³n y validando...")

# Â¡FIX DE VALUEERROR! (CreaciÃ³n correcta de 'indices')
s = pd.Series(df.index, index=df['title'])
indices = s[~s.index.duplicated(keep='first')] # Elimina tÃ­tulos duplicados
print("   > Mapeo de 'Ã­ndices' (sin duplicados) creado.")

def get_recommendations(title, cosine_sim_matrix=cosine_sim, num_recommendations=10):
    if title not in indices:
        matching_titles = [t for t in indices.index if title.lower() in str(t).lower()]
        if not matching_titles:
            return f"Error: No se encontrÃ³ '{title}' ni tÃ­tulos similares en el Top 10k."
        print(f"   > No se encontrÃ³ '{title}'. Mostrando resultados para '{matching_titles[0]}'")
        title = matching_titles[0]

    idx = indices[title]

    # Â¡FIX DE VALUEERROR! (El "seguro" por si acaso)
    if isinstance(idx, pd.Series):
        idx = idx.iloc[0]

    sim_scores = list(enumerate(cosine_sim_matrix[idx]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
    top_sim_scores = sim_scores[1 : num_recommendations + 1]
    movie_indices = [i[0] for i in top_sim_scores]
    return df['title'].iloc[movie_indices]

print("   > Â¡FunciÃ³n 'get_recommendations' (corregida) definida!")

# --- Â¡VALIDACIÃ“N FINAL! ---
print("\n--- [VALIDACIÃ“N CUALITATIVA DEL MODELO TOP 10K] ---")

movie_title_1 = 'The Dark Knight'
print(f"\nRecomendaciones para: '{movie_title_1}'")
print("------------------------------------------")
print(get_recommendations(movie_title_1))

movie_title_2 = 'Inception'
print(f"\nRecomendaciones para: '{movie_title_2}'")
print("------------------------------------------")
print(get_recommendations(movie_title_2))

movie_title_3 = 'Pulp Fiction'
print(f"\nRecomendaciones para: '{movie_title_3}'")
print("------------------------------------------")
print(get_recommendations(movie_title_3, num_recommendations=5))

movie_title_4 = 'A Nightmare on Elm Street'
print(f"\nRecomendaciones para: '{movie_title_4}'")
print("------------------------------------------")
print(get_recommendations(movie_title_4, num_recommendations=5))


# --- 10. GENERACIÃ“N DE LA MATRIZ DE COHERENCIA (VALIDACIÃ“N VISUAL) ---
print("\n[Paso 10/9] Generando Matriz de Coherencia de GÃ©neros...")

# Definimos pelÃ­culas representativas de gÃ©neros puros
test_movies_dict = {
    'Animation': 'Toy Story',
    'Horror': 'Scream',
    'Action': 'The Dark Knight',
    'Romance': 'Titanic',
    'Science Fiction': 'The Matrix' # Nota: En tu dataset puede estar como 'Science Fiction' o 'Sci-Fi'
}

# Preparamos la matriz
matrix_labels = list(test_movies_dict.keys())
coherence_matrix = pd.DataFrame(0, index=matrix_labels, columns=matrix_labels)

# Llenamos la matriz
for target_genre, title in test_movies_dict.items():
    # Obtenemos 10 recomendaciones
    # Nota: Usamos try/except por si el tÃ­tulo exacto no estÃ¡ en el Top 10k
    try:
        recs = get_recommendations(title, num_recommendations=10)

        # Si recs es string (mensaje de error), saltamos
        if isinstance(recs, str):
            continue

        for rec_title in recs:
            # Buscamos el gÃ©nero principal de la recomendaciÃ³n en el DF original
            rec_genres = df[df['title'] == rec_title]['genres_list'].iloc[0]

            # Verificamos si alguno de sus gÃ©neros coincide con nuestras columnas
            for g in rec_genres: # rec_genres ya es una lista gracias a tu paso 4
                # Mapeo manual rÃ¡pido por si hay variaciones (Sci-Fi vs Science Fiction)
                if g.lower() == 'sci-fi': g = 'Science Fiction'

                # Capitalizamos para coincidir con las columnas
                g_cap = g.title()
                if g == 'sciencefiction': g_cap = 'Science Fiction' # Tu limpieza quitÃ³ espacios

                # Buscamos coincidencia aproximada
                for label in matrix_labels:
                    if label.lower().replace(" ", "") in g.lower():
                        coherence_matrix.loc[target_genre, label] += 1
                        break # Contamos solo el gÃ©nero principal coincidente
    except Exception as e:
        print(f"Salto en {title}: {e}")

# Graficamos
plt.figure(figsize=(10, 8))
sns.heatmap(coherence_matrix, annot=True, cmap='Blues', fmt='g', linewidths=.5)
plt.title('Matriz de Coherencia: Â¿El modelo respeta los gÃ©neros?', fontsize=15)
plt.xlabel('GÃ©nero Recomendado', fontsize=12)
plt.ylabel('GÃ©nero de Entrada (Input)', fontsize=12)
plt.savefig('grafico_6_matriz_coherencia.png') # Â¡Guardamos la imagen!
plt.close()
print(" Â  > GrÃ¡fico 6 (Matriz de Coherencia) guardado.")



# --- 11. EXPORTAR MODELO PARA AWS (SERIALIZACIÃ“N) ---
print("\n[Paso 11/9] Guardando archivos para despliegue en Nube...")
import joblib

# Guardamos la matriz de similitud (El "cerebro" del modelo)
joblib.dump(cosine_sim, 'cosine_sim_model.pkl')

# Guardamos el dataframe reducido (Necesario para traducir Ã­ndice -> tÃ­tulo)
df[['title', 'genres_list']].to_pickle('movie_data.pkl')

# Guardamos los Ã­ndices
pd.Series(df.index, index=df['title']).drop_duplicates().to_pickle('indices.pkl')

print(" Â  > Archivos .pkl generados exitosamente (listos para subir a S3/EC2).")


print("\n--- [FIN] Â¡Sistema de recomendaciÃ³n completo! ---")